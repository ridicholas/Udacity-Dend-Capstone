{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Load Source Data"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "from datetime import datetime\nimport os\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import udf, col, monotonically_increasing_id, to_timestamp\nfrom pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format, lit\nfrom pyspark.sql import types\nimport pyspark.sql.functions as F", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#store source data filepaths\n\nbitstamp_path = \"s3n://udacity-dend-crypto/bitcoin-historical-data/bitstamp.csv\"\ncoinbase_path = \"s3n://udacity-dend-crypto/bitcoin-historical-data/coinbase.json\"", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#load data into Spark dataframes \n\nbitData = spark.read.csv(bitstamp_path, header = True)\ncoinData = spark.read.json(coinbase_path)\nbitData.persist()\ncoinData.persist()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Initial Data Exploration & Cleaning"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "bitData.printSchema()", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "coinData.printSchema()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "All columns are strings when they should not be, this will need to be corrected (Timestamp should be timestamp type, all others should be double type)"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#replace 'NaN' values with 0\n\ncoinData = coinData.replace('NaN','0')\nbitData = bitData.replace('NaN', '0')", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#convert all none-Timestamp columns to doubles\n\nfor col in coinData.columns:\n    if col != 'Timestamp':\n        coinData = coinData.withColumn(col, coinData[col].cast(types.DoubleType()))\n        bitData = bitData.withColumn(col, bitData[col].cast(types.DoubleType()))\n\ncoinData = coinData.withColumn(\"Timestamp\", coinData[\"Timestamp\"].cast(types.IntegerType()))\nbitData = bitData.withColumn(\"Timestamp\", bitData[\"Timestamp\"].cast(types.IntegerType()))\ncoinData = coinData.withColumn(\"Timestamp\", coinData[\"Timestamp\"].cast(types.TimestampType()))\nbitData = bitData.withColumn(\"Timestamp\", bitData[\"Timestamp\"].cast(types.TimestampType()))", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#check to see if everything worked\n\ncoinData.printSchema()\nbitData.printSchema()", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "coinData.show()", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "bitData.show()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Everything looks good, we can begin pipelining our data into the analytics tables"}, {"metadata": {}, "cell_type": "markdown", "source": "# Data Pipeline into Analytics tables"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Creating complete time table \n\ntime = coinData.select('Timestamp').union(bitData.select('Timestamp')).distinct().sort(\"Timestamp\", ascending = True)\ntime = time.withColumn(\"Date\", time[\"Timestamp\"].cast(types.DateType()))\ntime = time.withColumn(\"Month\", month(time[\"Timestamp\"]))\ntime = time.withColumn(\"DayOfMonth\", dayofmonth(time[\"Timestamp\"]))\ntime = time.withColumn(\"Year\", year(time[\"Timestamp\"]))\ntime = time.withColumn(\"Week\", weekofyear(time[\"Timestamp\"]))\ntime = time.withColumn(\"DayOfWeek\", F.dayofweek(time[\"Timestamp\"]))\ntime = time.withColumn(\"Hour\", hour(time[\"Timestamp\"]))\ntime = time.withColumn(\"Minute\", F.minute(time[\"Timestamp\"]))", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#write time table to parquet files\n\ntime.write.partitionBy(\"Year\",\"Month\",\"DayOfMonth\").parquet('s3n://udacity-dend-crypto/analytics/' + 'time')", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#Creating Markets table\n\nmarkets = sc.parallelize([{\"Market\": \"Coinbase\",\"Id\": 1}, {\"Market\": \"Bitstamp\", \"Id\":2}]).toDF()\nmarkets = markets.select(\"Id\", \"Market\")\n", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#write markets table to parquet files\n\n#markets.write.parquet('s3n://udacity-dend-crypto/analytics/' + 'markets')", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#Creating the transactions table\n\n\n#append appropriate market id to each source table\ncoinData = coinData.withColumn(\"marketId\", lit(1))\nbitData = bitData.withColumn(\"marketId\", lit(2))\n", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#colnames with _() cause problems, need to recreate with appropriate names\ncoinData = coinData.withColumn(\"VolBTC\", coinData[\"Volume_(BTC)\"])\ncoinData = coinData.withColumn(\"VolCurrency\", coinData[\"Volume_(Currency)\"])\nbitData = bitData.withColumn(\"VolBTC\", bitData[\"Volume_(BTC)\"])\nbitData = bitData.withColumn(\"VolCurrency\", bitData[\"Volume_(Currency)\"])", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#reorder and rename columns of our two source tables to allow union\n\nbitData = bitData.selectExpr(\"Timestamp\",\n                   \"marketID\",\n                   \"Close\",\n                   \"High\",\n                   \"Low\",\n                   \"Open\",\n                   \"VolBTC\",\n                   \"VolCurrency\",\n                   \"Weighted_Price as WeightedPrice\")\n\ncoinData = coinData.selectExpr(\"Timestamp\",\n                   \"marketID\",\n                   \"Close\",\n                   \"High\",\n                   \"Low\",\n                   \"Open\",\n                   \"VolBTC\",\n                   \"VolCurrency\",\n                   \"Weighted_Price as WeightedPrice\")\n", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#union our two source tables\n\ntransactions = coinData.unionAll(bitData)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#sort our table by timestamp\n\ntransactions = transactions.sort(\"Timestamp\", ascending = True)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#create transaction id column\n\ntransactions = transactions.withColumn(\"Id\", monotonically_increasing_id())", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#write transactions to parquet files\n#transactions.write.partitionBy('marketID').parquet('s3n://udacity-dend-crypto/analytics/' + 'transactions')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Data Quality Checks\n\nNow that our data has been loaded into the analytics schema parquet files, let's make sure everything loaded correctly by comparing the source files to the newly loaded parquet files"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#re-read data from source\n\nbitData = spark.read.csv(bitstamp_path, header = True)\ncoinData = spark.read.json(coinbase_path)\nbitData.persist()\ncoinData.persist()", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#read in analytics tables\n\ntime_path = \"s3n://udacity-dend-crypto/analytics/time\"\nmarket_path = \"s3n://udacity-dend-crypto/analytics/markets\"\ntransaction_path = \"s3n://udacity-dend-crypto/analytics/transactions\"\n\ntransactions = spark.read.parquet(transaction_path)\nmarkets = spark.read.parquet(market_path)\ntime_path = spark.read.parquet(time_path)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#compare total source file columns with transaction file columns (should be equal)\n\nprint(coinData.count() + bitData.count() == transactions.count())", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#check to see if time table contains correct number of timestamps\n\nsourceTimes = coinData.select('Timestamp').union(bitData.select('Timestamp')).distinct()\n", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "print(sourceTimes.count() == time.count())", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Awesome, looks like our data was transformed and loaded in correctly! "}, {"metadata": {}, "cell_type": "markdown", "source": "# Analytics\n\nNow let's put ourselves in the shoes of the analyst and see whether we can answer some analytical questions using the analytics schema. Say we are interested specifically in the year 2018:\n\n1. Can we get a month by month view comparing Bitstamp vs Coinbase Volume totals? \n2. Can we see which platform had higher volume for the whole of 2018?"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "transactions.createOrReplaceTempView(\"transactions\")\nmarkets.createOrReplaceTempView(\"markets\")\ntime.createOrReplaceTempView(\"time\")", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "Coin2018 = spark.sql('''\nSELECT ts.Year, ts.Month, sum(tr.VolBTC) as totalCoinbaseBTC\nFROM transactions tr JOIN time ts on tr.Timestamp = ts.Timestamp JOIN markets m on m.Id = tr.marketId\nWHERE ts.Year = 2018 and m.Market = \"Coinbase\"\nGROUP BY ts.Year, ts.Month\n''')\n\nBit2018 = spark.sql('''\nSELECT ts.Year, ts.Month, sum(tr.VolBTC) as totalBitstampBTC\nFROM transactions tr JOIN time ts on tr.Timestamp = ts.Timestamp JOIN markets m on m.Id = tr.marketId\nWHERE ts.Year = 2018 and m.Market = \"Bitstamp\"\nGROUP BY ts.Year, ts.Month\n''')\n\nentire2018 = Coin2018.join(Bit2018,\n                           Bit2018.Month == Coin2018.Month).select(Bit2018.Year,\n                                                                   Coin2018.Month,\n                                                                   \"totalCoinbaseBTC\",\n                                                                   \"totalBitstampBTC\").sort(\"Month\", ascending = True).persist()", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "entire2018.show()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Awesome, we have a monthly view of coinbase and bitstamp totals! Keep in mind this was put together by to the minute annual data consisting of more than 6 million rows! "}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "entire2018.groupBy(\"Year\").sum(\"TotalCOinbaseBTC\", \"totalBitstampBTC\").show()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "We were also able to quickly aggregate the monthly information into yearly totals! Looks like Coinbase wins! "}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "pysparkkernel", "display_name": "PySpark", "language": ""}, "language_info": {"name": "pyspark", "mimetype": "text/x-python", "codemirror_mode": {"name": "python", "version": 2}, "pygments_lexer": "python2"}}, "nbformat": 4, "nbformat_minor": 2}